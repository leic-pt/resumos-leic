name: Search scraping

concurrency: search_scraping
on: deployment_status

jobs:
  scrape-site-for-search:
    name: 'Scrape Site for Search'
    if: github.event.deployment_status.state == 'success' && github.event.deployment.environment == 'production'
    runs-on: ubuntu-20.04
    steps:
      - uses: actions/checkout@master
      - name: Run docs-scraper
        env:
          HOST_URL: ${{ secrets.MEILISEARCH_HOST_URL }}
          API_KEY: ${{ secrets.MEILISEARCH_API_KEY }}
          CONFIG_FILE_PATH: ${{ github.workspace }}/.github/workflows/docs-scraper.config.json
        run: |
          docker run -t --rm \
            -e MEILISEARCH_HOST_URL=$HOST_URL \
            -e MEILISEARCH_API_KEY=$API_KEY \
            -v $CONFIG_FILE_PATH:/docs-scraper/config.json \
            getmeili/docs-scraper:v0.10.4 pipenv run ./docs_scraper config.json

# TODO enable filtering for hierarchy_lvl0
